<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script>
(function() {
  function addWidgetsRenderer() {
    var mimeElement = document.querySelector('script[type="application/vnd.jupyter.widget-view+json"]');
    var scriptElement = document.createElement('script');
    var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js';
    var widgetState;

    // Fallback for older version:
    try {
      widgetState = mimeElement && JSON.parse(mimeElement.innerHTML);

      if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) {
        widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js';
      }
    } catch(e) {}

    scriptElement.src = widgetRendererSrc;
    document.body.appendChild(scriptElement);
  }

  document.addEventListener('DOMContentLoaded', addWidgetsRenderer);
}());
</script>

<div class="cell border-box-sizing text_cell rendered" markdown="1">
<div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1">
# Larq Zoo Tutorial

<a href="https://mybinder.org/v2/gh/larq/docs/master?filepath=docs%2Fzoo%2Ftutorials.ipynb"><button class="notebook-badge">Run on Binder</button></a> <a href="https://github.com/larq/docs/blob/master/docs/zoo/tutorials.ipynb"><button class="notebook-badge">View on GitHub</button></a>

This tutorial demonstrates how to load pretrained models from Larq Zoo. These models can be used for prediction, feature extraction, and fine-tuning.
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" markdown="1">
<div class="input">

```python
import tensorflow as tf
import tensorflow_datasets as tfds
import numpy as np
import larq_zoo as lqz
from urllib.request import urlopen
```

</div>

</div>
<div class="cell border-box-sizing text_cell rendered" markdown="1">
<div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1">
### Download and prepare a sample image

In the following we will use a sample image from the [ImageNet](http://image-net.org/) dataset:
<img src="https://raw.githubusercontent.com/larq/zoo/master/tests/fixtures/elephant.jpg" width="50%">
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" markdown="1">
<div class="input">

```python
img_path = "https://raw.githubusercontent.com/larq/zoo/master/tests/fixtures/elephant.jpg"

with urlopen(img_path) as f:
    img = tf.keras.preprocessing.image.load_img(f, target_size=(224, 224))

x = tf.keras.preprocessing.image.img_to_array(img)
x = lqz.preprocess_input(x)
x = np.expand_dims(x, axis=0)
```

</div>

</div>
<div class="cell border-box-sizing text_cell rendered" markdown="1">
<div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1">
### Classify ImageNet classes with Bi-Real Net

We will first load the Bi-Real Net architecture with pretrained weights and predict the image class.
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" markdown="1">
<div class="input">

```python
model = lqz.literature.BiRealNet(weights="imagenet")
preds = model.predict(x)
lqz.decode_predictions(preds, top=5)[0]
```

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">


<div class="output_text output_subarea output_execute_result">
<pre>
<code>[(&#39;n02504458&#39;, &#39;African_elephant&#39;, 0.7529364),
 (&#39;n01871265&#39;, &#39;tusker&#39;, 0.22607337),
 (&#39;n02504013&#39;, &#39;Indian_elephant&#39;, 0.017037684),
 (&#39;n02410509&#39;, &#39;bison&#39;, 0.0016636014),
 (&#39;n02412080&#39;, &#39;ram&#39;, 0.0014974006)]</code>
</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered" markdown="1">
<div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1">
### Extract features with Bi-Real Net

Larq Zoo models can also be used to extract features that can be used as input to a second model.
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" markdown="1">
<div class="input">

```python
tf.keras.backend.clear_session()
model = lqz.literature.BiRealNet(weights="imagenet", include_top=False)
features = model.predict(x)
print("Feature shape:", features.shape)
```

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>Feature shape: (1, 7, 7, 512)
</code>
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered" markdown="1">
<div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1">
### Extract features from an arbitrary intermediate layer

Features can also be extracted from arbitrary intermediate layer with just a few lines of code.
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" markdown="1">
<div class="input">

```python
avg_pool_layer = model.get_layer("average_pooling2d_2")
avg_pool_model = tf.keras.models.Model(
    inputs=model.input, outputs=avg_pool_layer.output)

avg_pool_features = avg_pool_model.predict(x)
print("average_pooling2d_2 feature shape:", avg_pool_features.shape)
```

</div>

<div class="output_wrapper" markdown="1">
<div class="output" markdown="1">


<div class="output_area" markdown="1">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>average_pooling2d_2 feature shape: (1, 7, 7, 256)
</code>
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered" markdown="1">
<div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1">
### Build Bi-Real Net over a custom input Tensor

The model can also be used with an input Tensor that might also be the output a different Keras model or layer.
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" markdown="1">
<div class="input">

```python
input_tensor = tf.keras.layers.Input(shape=(224, 224, 3))

model = lqz.literature.BiRealNet(input_tensor=input_tensor, weights="imagenet")
```

</div>

</div>
<div class="cell border-box-sizing text_cell rendered" markdown="1">
<div class="inner_cell" markdown="1">
<div class="text_cell_render border-box-sizing rendered_html" markdown="1">
### Evaluate Bi-Real Net with TensorFlow Datasets

To re-run the evaluation on the entire [ImageNet](http://image-net.org/) validation dataset [Tensorflow Datasets](https://www.tensorflow.org/datasets/) can be used.

Note that running this example will require [**mannualy downloading**](https://www.tensorflow.org/datasets/catalog/imagenet2012) the entire dataset and might take a very long time to complete.
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered" markdown="1">
<div class="input">

```python
def preprocess(data):
    img = lqz.preprocess_input(data["image"])
    label = tf.one_hot(data["label"], 1000)
    return img, label 

dataset = (
    tfds.load("imagenet2012:5.0.0", split=tfds.Split.VALIDATION)
    .map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    .batch(128)
    .prefetch(1)
)

model = lqz.literature.BiRealNet()
model.compile(
    optimizer="sgd",
    loss="categorical_crossentropy",
    metrics=["categorical_accuracy", "top_k_categorical_accuracy"],
)

model.evaluate(dataset)
```

</div>

</div>


