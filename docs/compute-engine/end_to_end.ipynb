{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitvenvvenvc6a0c56cef40423dadad7c09f704025c",
   "display_name": "Python 3.8.2 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "These steps will walk you through deploying a BNN with LCE. The guide starts by downloading, converting and benchmarking a model from [Larq Zoo](https://docs.larq.dev/zoo/), and will then discuss the process for a custom model.\n",
    "\n",
    "## 1. Picking a model from Larq Zoo\n",
    "This example uses the [QuickNet model](https://docs.larq.dev/zoo/api/sota/#quicknet) from the `sota` submodule of `larq-zoo`.\n",
    "First, install the Larq Ecosystem pip packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install larq larq-zoo larq-compute-engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create a python script that will download QuickNet and print the model summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+quicknet stats----------------------------------------------------------------------------------------------------+\n| Layer                   Input prec.                 Outputs  # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |\n|                               (bit)                              x 1       x 1     (kB)                          |\n+------------------------------------------------------------------------------------------------------------------+\n| input_1                           -  ((None, 224, 224, 3),)        0         0        0           ?            ? |\n| conv2d                            -       (-1, 112, 112, 8)        0       216     0.84           0      2709504 |\n| depthwise_conv2d                  -        (-1, 56, 56, 64)        0       576     2.25           0      1806336 |\n| batch_normalization               -        (-1, 56, 56, 64)        0       128     0.50           0            0 |\n| quant_conv2d                      1        (-1, 56, 56, 64)    36864         0     4.50   115605504            0 |\n| batch_normalization_1             -        (-1, 56, 56, 64)        0       128     0.50           0            0 |\n| add                               -        (-1, 56, 56, 64)        0         0        0           ?            ? |\n| quant_conv2d_1                    1        (-1, 56, 56, 64)    36864         0     4.50   115605504            0 |\n| batch_normalization_2             -        (-1, 56, 56, 64)        0       128     0.50           0            0 |\n| add_1                             -        (-1, 56, 56, 64)        0         0        0           ?            ? |\n| max_pooling2d                     -        (-1, 28, 28, 64)        0         0        0           0            0 |\n| quant_conv2d_2                    1        (-1, 28, 28, 64)    36864         0     4.50    28901376            0 |\n| batch_normalization_3             -        (-1, 28, 28, 64)        0       128     0.50           0            0 |\n| batch_normalization_4             -        (-1, 28, 28, 64)        0       128     0.50           0            0 |\n| add_2                             -        (-1, 28, 28, 64)        0         0        0           ?            ? |\n| concatenate                       -       (-1, 28, 28, 128)        0         0        0           ?            ? |\n| quant_conv2d_3                    1       (-1, 28, 28, 128)   147456         0    18.00   115605504            0 |\n| batch_normalization_5             -       (-1, 28, 28, 128)        0       256     1.00           0            0 |\n| add_3                             -       (-1, 28, 28, 128)        0         0        0           ?            ? |\n| quant_conv2d_4                    1       (-1, 28, 28, 128)   147456         0    18.00   115605504            0 |\n| batch_normalization_6             -       (-1, 28, 28, 128)        0       256     1.00           0            0 |\n| add_4                             -       (-1, 28, 28, 128)        0         0        0           ?            ? |\n| max_pooling2d_1                   -       (-1, 14, 14, 128)        0         0        0           0            0 |\n| quant_conv2d_5                    1       (-1, 14, 14, 128)   147456         0    18.00    28901376            0 |\n| batch_normalization_7             -       (-1, 14, 14, 128)        0       256     1.00           0            0 |\n| batch_normalization_8             -       (-1, 14, 14, 128)        0       256     1.00           0            0 |\n| add_5                             -       (-1, 14, 14, 128)        0         0        0           ?            ? |\n| concatenate_1                     -       (-1, 14, 14, 256)        0         0        0           ?            ? |\n| quant_conv2d_6                    1       (-1, 14, 14, 256)   589824         0    72.00   115605504            0 |\n| batch_normalization_9             -       (-1, 14, 14, 256)        0       512     2.00           0            0 |\n| add_6                             -       (-1, 14, 14, 256)        0         0        0           ?            ? |\n| quant_conv2d_7                    1       (-1, 14, 14, 256)   589824         0    72.00   115605504            0 |\n| batch_normalization_10            -       (-1, 14, 14, 256)        0       512     2.00           0            0 |\n| add_7                             -       (-1, 14, 14, 256)        0         0        0           ?            ? |\n| quant_conv2d_8                    1       (-1, 14, 14, 256)   589824         0    72.00   115605504            0 |\n| batch_normalization_11            -       (-1, 14, 14, 256)        0       512     2.00           0            0 |\n| add_8                             -       (-1, 14, 14, 256)        0         0        0           ?            ? |\n| max_pooling2d_2                   -         (-1, 7, 7, 256)        0         0        0           0            0 |\n| quant_conv2d_9                    1         (-1, 7, 7, 256)   589824         0    72.00    28901376            0 |\n| batch_normalization_12            -         (-1, 7, 7, 256)        0       512     2.00           0            0 |\n| batch_normalization_13            -         (-1, 7, 7, 256)        0       512     2.00           0            0 |\n| add_9                             -         (-1, 7, 7, 256)        0         0        0           ?            ? |\n| concatenate_2                     -         (-1, 7, 7, 512)        0         0        0           ?            ? |\n| quant_conv2d_10                   1         (-1, 7, 7, 512)  2359296         0   288.00   115605504            0 |\n| batch_normalization_14            -         (-1, 7, 7, 512)        0      1024     4.00           0            0 |\n| add_10                            -         (-1, 7, 7, 512)        0         0        0           ?            ? |\n| quant_conv2d_11                   1         (-1, 7, 7, 512)  2359296         0   288.00   115605504            0 |\n| batch_normalization_15            -         (-1, 7, 7, 512)        0      1024     4.00           0            0 |\n| add_11                            -         (-1, 7, 7, 512)        0         0        0           ?            ? |\n| quant_conv2d_12                   1         (-1, 7, 7, 512)  2359296         0   288.00   115605504            0 |\n| batch_normalization_16            -         (-1, 7, 7, 512)        0      1024     4.00           0            0 |\n| add_12                            -         (-1, 7, 7, 512)        0         0        0           ?            ? |\n| activation                        -         (-1, 7, 7, 512)        0         0        0           ?            ? |\n| average_pooling2d                 -         (-1, 1, 1, 512)        0         0        0           0            0 |\n| flatten                           -               (-1, 512)        0         0        0           0            0 |\n| dense                             -              (-1, 1000)        0    513000  2003.91           0       512000 |\n| activation_1                      -              (-1, 1000)        0         0        0           ?            ? |\n+------------------------------------------------------------------------------------------------------------------+\n| Total                                                        9990144    521088  3255.00  1242759168      5027840 |\n+------------------------------------------------------------------------------------------------------------------+\n+quicknet summary-----------------------------+\n| Total params                      10.5 M    |\n| Trainable params                  10.5 M    |\n| Non-trainable params              7.3 k     |\n| Model size                        3.18 MiB  |\n| Model size (8-bit FP weights)     1.69 MiB  |\n| Float-32 Equivalent               40.10 MiB |\n| Compression Ratio of Memory       0.08      |\n| Number of MACs                    1.25 B    |\n| Ratio of MACs that are binarized  0.9960    |\n+---------------------------------------------+\n"
    }
   ],
   "source": [
    "import larq as lq\n",
    "import larq_compute_engine as lce\n",
    "import larq_zoo as lqz\n",
    "\n",
    "\n",
    "# Load the QuickNet architecture and download the weights for ImageNet\n",
    "model = lqz.sota.QuickNet(weights=\"imagenet\")\n",
    "lq.models.summary(model)\n",
    "model.save(\"quicknet.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the model size is 3.18 MiB, but the float-32 model size is 40.10 MiB. Indeed, if you look at the `quicknet.h5` file you just saved, you'll see that it is around 42 MiB in size. This is because the model is currently unoptimized and the weights are still stored as floats rather than binary values, so executing this model on any device wouldn't be very fast at all. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Converting the model\n",
    "Larq Compute Engine is built on top of TensorFlow Lite, and therefore uses the [TensorFlow Lite FlatBuffer format](https://google.github.io/flatbuffers/) to convert and serialize Larq models for inference. We provide our own [LCE Model Converter](https://docs.larq.dev/compute-engine/api/converter/) to convert models from Keras to flatbuffers, containing additional optimization passes that increase the execution speed of Larq models on the supported target platforms. \n",
    "\n",
    "Using this converter is very simple, and can be done by adding the following code to the python script above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"quicknet.tflite\", \"wb\") as flatbuffer_file:\n",
    "    # Convert our Keras model to a TFLite flatbuffer file\n",
    "    flatbuffer_bytes = lce.convert_keras_model(model)\n",
    "    flatbuffer_file.write(flatbuffer_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will produce the converted `quicknet.tflite` file with compressed weights and optimized operations, which is only just over 3 MiB in size!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Benchmarking\n",
    "This part of the guide assumes that you'll want to benchmark on an Arm-64 based board such as a Raspberry Pi. For more detailed instructions on benchmarking, see the [Benchmarking guide](https://docs.larq.dev/compute-engine/benchmark).\n",
    "\n",
    "On Arm64, benchmarking is as simple as downloading the pre-built benchmarking binary from the [latest release](https://github.com/larq/compute-engine/releases/latest) to the target device and running it with the converted model:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "STARTING!\nDuplicate flags: num_threads\nMin num runs: [50]\nMin runs duration (seconds): [1]\nMax runs duration (seconds): [150]\nInter-run delay (seconds): [-1]\nNum threads: [1]\n...\n...\nLoaded model quicknet.tflite\nThe input model file size (MB): 3.34914\nInitialized session in 3.501ms.\nRunning benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.\ncount=12 first=156677 curr=33205 min=32578 max=156677 avg=43268.1 std=34197\n\nRunning benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.\ncount=50 first=33228 curr=33130 min=32687 max=33239 avg=33071.8 std=129\n\nInference timings in us: Init: 3501, First inference: 156677, Warmup (avg): 43268.1, Inference (avg): 33071.8"
    }
   ],
   "source": [
    "!wget <TODO-URL> -o benchmark_model\n",
    "!chmod +x benchmark_model\n",
    "!./benchmark_model --graph=quicknet.tflite --num_runs=50 --num_threads=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of interest here is `Inference (avg)`, which in this case is 33.1 ms (33071.8 microseconds) on a [Raspberry Pi 4B](https://www.raspberrypi.org/documentation/hardware/raspberrypi/bcm2711/README.md).\n",
    "\n",
    "To see the other available benchmarking options, add `--help` to the command above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create your own Larq model\n",
    "TODO"
   ]
  }
 ]
}
